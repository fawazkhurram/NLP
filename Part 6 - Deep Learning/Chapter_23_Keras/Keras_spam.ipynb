{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Example\n",
    "\n",
    "Using an SMS Spam data set (slightly modified) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data set is a collection of 5574 SMS messages that have been labeled as ham or spam. The file is a tab-delimited file with the first column the label and the second the message content. I edited the data set to remove some unwanted columns and add headings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# some necessary packages\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows and columns: (4837, 2)\n",
      "   spam                                               text\n",
      "0     0  Go until jurong point, crazy.. Available only ...\n",
      "1     0                      Ok lar... Joking wif u oni...\n",
      "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3     0  U dun say so early hor... U c already then say...\n",
      "4     0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sms-spam.csv', header=0, usecols=[1,2], encoding='latin-1')\n",
    "print('rows and columns:', df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  (3856, 2)\n",
      "test data size:  (981, 2)\n"
     ]
    }
   ],
   "source": [
    "# split df into train and test\n",
    "i = np.random.rand(len(df)) < 0.8\n",
    "train = df[i]\n",
    "test = df[~i]\n",
    "print(\"train data size: \", train.shape)\n",
    "print(\"test data size: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes: (3856, 25000) (3856,)\n",
      "test shapes: (981, 25000) (981,)\n",
      "test first five labels: [0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# set up X and Y\n",
    "num_labels = 2\n",
    "vocab_size = 25000\n",
    "batch_size = 100\n",
    "\n",
    "# fit the tokenizer on the training data\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(train.text)\n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(train.text, mode='tfidf')\n",
    "x_test = tokenizer.texts_to_matrix(test.text, mode='tfidf')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train.spam)\n",
    "y_train = encoder.transform(train.spam)\n",
    "y_test = encoder.transform(test.spam)\n",
    "\n",
    "# check shape\n",
    "print(\"train shapes:\", x_train.shape, y_train.shape)\n",
    "print(\"test shapes:\", x_test.shape, y_test.shape)\n",
    "print(\"test first five labels:\", y_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1114 17:15:13.621602 139652879566656 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1114 17:15:13.888079 139652879566656 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3470 samples, validate on 386 samples\n",
      "Epoch 1/30\n",
      "3470/3470 [==============================] - 1s 263us/step - loss: 0.5447 - accuracy: 0.8418 - val_loss: 0.4008 - val_accuracy: 0.8938\n",
      "Epoch 2/30\n",
      "3470/3470 [==============================] - 1s 162us/step - loss: 0.2937 - accuracy: 0.9248 - val_loss: 0.2233 - val_accuracy: 0.9534\n",
      "Epoch 3/30\n",
      "3470/3470 [==============================] - 1s 164us/step - loss: 0.1367 - accuracy: 0.9833 - val_loss: 0.1269 - val_accuracy: 0.9793\n",
      "Epoch 4/30\n",
      "3470/3470 [==============================] - 1s 157us/step - loss: 0.0640 - accuracy: 0.9968 - val_loss: 0.0950 - val_accuracy: 0.9845\n",
      "Epoch 5/30\n",
      "3470/3470 [==============================] - 1s 157us/step - loss: 0.0363 - accuracy: 0.9974 - val_loss: 0.0847 - val_accuracy: 0.9870\n",
      "Epoch 6/30\n",
      "3470/3470 [==============================] - 1s 161us/step - loss: 0.0228 - accuracy: 0.9986 - val_loss: 0.0810 - val_accuracy: 0.9870\n",
      "Epoch 7/30\n",
      "3470/3470 [==============================] - 1s 161us/step - loss: 0.0156 - accuracy: 0.9997 - val_loss: 0.0789 - val_accuracy: 0.9870\n",
      "Epoch 8/30\n",
      "3470/3470 [==============================] - 1s 161us/step - loss: 0.0115 - accuracy: 0.9997 - val_loss: 0.0793 - val_accuracy: 0.9870\n",
      "Epoch 9/30\n",
      "3470/3470 [==============================] - 1s 158us/step - loss: 0.0089 - accuracy: 0.9997 - val_loss: 0.0800 - val_accuracy: 0.9870\n",
      "Epoch 10/30\n",
      "3470/3470 [==============================] - 1s 161us/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.0800 - val_accuracy: 0.9870\n",
      "Epoch 11/30\n",
      "3470/3470 [==============================] - 1s 159us/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.0815 - val_accuracy: 0.9870\n",
      "Epoch 12/30\n",
      "3470/3470 [==============================] - 1s 160us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9870\n",
      "Epoch 13/30\n",
      "3470/3470 [==============================] - 1s 159us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9870\n",
      "Epoch 14/30\n",
      "3470/3470 [==============================] - 1s 162us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9870\n",
      "Epoch 15/30\n",
      "3470/3470 [==============================] - 1s 161us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9870\n",
      "Epoch 16/30\n",
      "3470/3470 [==============================] - 1s 157us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9870\n",
      "Epoch 17/30\n",
      "3470/3470 [==============================] - 1s 163us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9870\n",
      "Epoch 18/30\n",
      "3470/3470 [==============================] - 1s 162us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9870\n",
      "Epoch 19/30\n",
      "3470/3470 [==============================] - 1s 162us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9870\n",
      "Epoch 20/30\n",
      "3470/3470 [==============================] - 1s 165us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9870\n",
      "Epoch 21/30\n",
      "3470/3470 [==============================] - 1s 162us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9870\n",
      "Epoch 22/30\n",
      "3470/3470 [==============================] - 1s 164us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9870\n",
      "Epoch 23/30\n",
      "3470/3470 [==============================] - 1s 160us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9870\n",
      "Epoch 24/30\n",
      "3470/3470 [==============================] - 1s 158us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9870\n",
      "Epoch 25/30\n",
      "3470/3470 [==============================] - 1s 160us/step - loss: 9.9666e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9870\n",
      "Epoch 26/30\n",
      "3470/3470 [==============================] - 1s 161us/step - loss: 9.2100e-04 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9870\n",
      "Epoch 27/30\n",
      "3470/3470 [==============================] - 1s 167us/step - loss: 8.5346e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9870\n",
      "Epoch 28/30\n",
      "3470/3470 [==============================] - 1s 263us/step - loss: 7.9373e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9870\n",
      "Epoch 29/30\n",
      "3470/3470 [==============================] - 1s 250us/step - loss: 7.3996e-04 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9870\n",
      "Epoch 30/30\n",
      "3470/3470 [==============================] - 1s 223us/step - loss: 6.9075e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "# fit Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=vocab_size, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 0s 124us/step\n",
      "Accuracy:  0.9847095012664795\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14624296876466117, 0.9847095012664795]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions so we can calculate more metrics\n",
    "pred = model.predict_classes(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9847094801223242\n",
      "precision score:  0.9916666666666667\n",
      "recall score:  0.8947368421052632\n",
      "f1 score:  0.9407114624505929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred))\n",
    "print('recall score: ', recall_score(y_test, pred))\n",
    "print('f1 score: ', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was by far the most accurate. Much more work could be done modifying the network topology. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
